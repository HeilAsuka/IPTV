name: Run Scraping and Commit Changes

on:
  schedule:
    - cron: '0 10 * * *'  # UTC 时间上午10点（北京时间晚上6点
  workflow_dispatch:  # 允许手动触发

jobs:
  scrape:
    runs-on: ubuntu-latest  # 使用 Ubuntu 最新版本的 GitHub Runner

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2  # 克隆仓库

    - name: Set up Python environment
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'  # 可以根据需要选择合适的 Python 版本

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install --no-cache-dir -r requirements.txt
        pip install --no-cache-dir playwright
        python -m playwright install  # 安装 Playwright 需要的浏览器

    - name: Run the scraper
      run: |
        python main.py  # 运行爬虫脚本

    - name: Check for changes in scraped data
      id: check_changes
      run: |
        git status  # 输出当前文件的状态，检查是否有变动
        git diff --exit-code || echo "Changes detected"  # 如果有变化，输出 "Changes detected"
      
    - name: Commit and push changes
      if: steps.check_changes.outputs.exit_code != 0  # 只有当有变化时才执行提交
      run: |
        git status  # 查看当前文件状态
        git diff  # 输出文件差异，确保有变化
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        git add .  # 添加所有文件的变化
        git status  # 输出 git 状态，确保有文件被添加
        git commit -m "Upload scraped data" || echo "No changes to commit"  # 如果没有变化则跳过提交
        git push || echo "No changes to push"  # 如果没有变化则跳过推送
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # 自动授权 GitHub Actions 提交代码
