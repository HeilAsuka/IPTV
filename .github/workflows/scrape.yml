name: Run Scraping and Commit Changes

on:
  push:
    branches:
      - main  # 触发 main 分支的推送
  pull_request:
    branches:
      - main  # 触发向 main 分支的拉取请求

jobs:
  scrape:
    runs-on: ubuntu-latest  # 使用 Ubuntu 最新版本的 GitHub Runner

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2  # 克隆仓库

    - name: Set up Python environment
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'  # 可以根据需要选择合适的 Python 版本

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install --no-cache-dir -r requirements.txt
        pip install --no-cache-dir playwright
        python -m playwright install chromium  # 安装 Playwright 需要的浏览器

    - name: Run the scraper
      run: |
        python main.py  # 运行爬虫脚本

    - name: Check for changes in scraped data
      id: check_changes
      run: |
        # 检查根目录和 data 目录下的文件是否有变动
        git diff --exit-code || echo "Changes detected"  # 如果有变化，输出 "Changes detected"

    - name: Commit and push changes
      if: steps.check_changes.outputs.exit_code != 0  # 只有当有变化时才执行提交
      run: |
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        git add .  # 添加所有文件的变化
        git commit -m "Upload scraped data"
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # 自动授权 GitHub Actions 提交代码
